[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "1 Assignments\n\nExpected value, variance, standard deviation:\n\nExpected value of\n\nage: \\(E[age] = 33.471\\)\nincome: \\(E[income] = 3510.731\\)\n\nVariance of\n\nage: \\(Var[age] = 340.6078\\)\nincome: \\(Var[income] = 8625646\\)\n\nStandard deviation of\n\nage: \\(\\sigma = 18.45556\\)\nincome: \\(\\sigma = 2936.945\\)\n\n\n\n\n# Functions used in R for the computation\nrandom_vars &lt;- readRDS(\"files/random_vars.rds\")\n# Expected value of \"age\"\nE_age &lt;- mean(unlist(random_vars[\"age\"]))\n# Expected value of \"income\"\nE_income &lt;- mean(unlist(random_vars[\"income\"]))\n# Variance of \"age\"\nVar_age &lt;- var(random_vars[\"age\"])\n# Variance of \"income\"\nVar_income &lt;- var(random_vars[\"income\"])\n# Standard deviation of \"age\"\nStdev_age &lt;- sd(unlist(random_vars[\"age\"]))\n# Standard deviation of \"income\"\nStdev_income &lt;- sd(unlist(random_vars[\"income\"]))\n\n\nComparing standard deviations between age and income may not provide meaningful insights. The two variables are different types of data, thus they have different ranges. Age has a range from 0 to 99, but income has a range from 0 to 10485. Furthermore, both variables have different measure units. Age is measured in years and income is measured in a type of currency. This makes their standard deviations also to have different unit, thus they are not comparable to each other.\nCovariance, correlation:\n\nCovariance: \\(Cov(age,income) = 29700.15\\)\nCorrelation: \\(Corr(age,income) = 0.5479432\\)\n\n\nBoth the covariance and correlation indicate a positive linear relationship between age and income. In other words, on average, when age increases, income increases proportionally.\n\n# Functions used in R for the computation\n# Covariance\nCovariance &lt;- cov(random_vars[\"age\"], random_vars[\"income\"])\n# Correlation\nCorrelation &lt;- cor(random_vars[\"age\"], random_vars[\"income\"])\n\n\nCorrelation is easier to interpret than covariance. Since correlation is a standardized measure ranges from -1 to 1, one can find out the strength of the relationship between two variables in addition to its direction. The closer the absolute value of correlation is to 1, the stronger the relationship. In contrast, covariance is not a standardized measure, since its values don’t have a specific range. Covariance only provides information to the direction of the relationship.\nConditional expected value\n\n\\(E[income|age&lt;=18] = 389.6074\\)\n\\(E[income|age \\in [18,65)] = 4685.734\\)\n\\(E[income|age&gt;=65] = 1777.237\\)\n\n\n\n# Functions used in R for the computation\n# Expected value of income with age under or equal 18\nE_1 &lt;- mean(unlist(random_vars[random_vars$age &lt;= 18,\"income\"]))\n# Expected value of income with age above or equal 18 AND under 65\nE_2 &lt;- mean(unlist(random_vars[random_vars$age &gt;= 18 & random_vars$age &lt; 65,\"income\"]))\n# Expected value of income with age above or equal 65\nE_3 &lt;- mean(unlist(random_vars[random_vars$age &gt;= 65,\"income\"]))"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "1 Assignment\n\nmozzarella &lt;- c(9.3, 9.7, 9.7, 9.7, 9.9, 10.2, 10.5, 11, 10.6, 10.6)\ndoctorates &lt;- c(480, 501, 540, 552, 547, 622, 655, 701, 712, 708)\nyear &lt;- c(2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009)\ncor_data &lt;- data.frame(year, mozzarella, doctorates)\nylim.prim &lt;- c(9, 12)\nylim.sec &lt;- c(400, 1000)\nb &lt;- diff(ylim.prim)/diff(ylim.sec)\na &lt;- (ylim.prim[1] - b*ylim.sec[1])\nbasic &lt;- ggplot(cor_data, aes(x=year, y=mozzarella, color = \"Mozzarella consumption\")) + geom_line() + geom_point() + geom_line(aes(y = a + doctorates*b, color = \"Test\"), color = \"cyan3\") + geom_point(aes(y = a + doctorates*b), color = \"cyan3\") + scale_y_continuous(\"Mozzarella cheese consumption\", sec.axis = sec_axis(~ (. - a)/b, name = \"Engineering doctorates\")) + scale_x_continuous(\"Year\", breaks = cor_data$year) + ggtitle(\"Per capita consumption of mozzarella cheese\\n correlates with\\nCivil engineering doctorates awarded\") + theme(plot.title = element_text(hjust=0.5, face=\"bold\"))\nbasic + labs(color=\"Legend\")\n\n\n\n\n\n\n\n\nCorrelation: 95.86% (r=0.958648)\n\ncor(mozzarella, doctorates)\n\n#&gt; [1] 0.9586478"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "1 Assignments\n\nDAG of the parking spots example\n\n\n# parking spots \nparking_spots &lt;- dagify(\n  Y ~ X,\n  coords = list(x = c(X = 1, Y = 3),\n                y = c(X = 1, Y = 1)),\n  labels = list(X = \"having parking spots\",\n                Y = \"sales\")\n)\n\n# Plot DAG\nggdag(parking_spots) +\n  theme_dag() +\n  geom_dag_point(color = \"lightblue\") +\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges(edge_color = \"black\") +\n  geom_dag_label_repel(aes(label = label))\n\n\n\n\n\n\n\n\n\nCustomer satisfaction\n\nRegress satisfaction on follow_ups\n\n\n\n\n\nlm_sat_fol &lt;- lm(satisfaction ~ follow_ups, data = customer_sat)\nsummary(lm_sat_fol)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\n\n\nRegress satisfaction on follow_ups and account for subscription\n\n\n\nlm_sat_fol_subs &lt;- lm(satisfaction ~ follow_ups + subscription, data = customer_sat)\nsummary(lm_sat_fol_subs)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\nThe coefficient in the first case (Regress satisfaction on follow_ups) is negative, meaning an increase in follow-up calls is related to a decrease in satisfaction. However, when we account for subscription in the linear regression, the coefficient indicates a positive linear relationship between follow-up calls and satisfaction. This is due to the fact that the number of follow-up calls depends on the subscription, which also affects the satisfaction degree. Thus, subscription is a cofounder and we would result in an incorrect result if we do not account for subscription when performing regression. The DAG for the example looks like this\n\n\n\n\n\n\n\n\n\nLooking at the DAG above, we see that there is an indirect effect induced by subscription on the direct causal effect of follow_ups on satisfaction. The indirect effect is a spurious correlation which is irrelevant for our research, but can falsify our results if we do not conditioned on it. By accounting for subscription when regressing satisfaction on follow_ups, we condition on subscription and keep it at a fixed value. Thus, the values of satisfaction are purely dependent on the values of follow_ups, and we are able to retrieve the causal effect from follow_ups to satisfaction.\n\nPlot\n\n\nggplot(customer_sat, aes(x = follow_ups, y = satisfaction,)) +\n  geom_point(color = \"cornflowerblue\") +\n  stat_smooth(method = \"lm\", se = F, color = \"coral2\", formula = y ~ x)\n\n\n\n\n\n\n\n\nggplot(customer_sat, aes(x = follow_ups, y = satisfaction,\n                            color = subscription, \n                            alpha = subscription)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F, formula = y ~ x) +\n  scale_color_manual(values = c(\"Premium\"=\"darkolivegreen3\",\n                                \"Premium+\"=\"cornflowerblue\",\n                                \"Elite\"=\"coral2\")) +\n  scale_alpha_manual(values = c(1,1, 1)) +\n  theme(legend.position = \"right\")"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "1 Assignments\n\nCovariates Balance Plots\n\n\nm.out &lt;- MatchIt::matchit(chatbot ~ previous_visit + mobile_device, data = abtest_online)\nbal.plot(m.out, var.name = \"previous_visit\")\n\n\n\n\n\n\nbal.plot(m.out, var.name = \"mobile_device\")\n\n\n\n\n\n\n\nFrom the plots we observe that in general, the covariates are balanced across the groups. However, for previous_visit there are slightly fewer control units than treated units so that not all units get a match. Especially, the plot “Distributional Balance for previous_visit” shows that the from previous_visit = 7, there are no control units matched to the treated units.\n\nRegress chatbot on purchase_amount\n\n\n\n# Functions used in R for the task\nlm_sales &lt;- lm(purchase_amount ~ chatbot, data = abtest_online)\nsummary(lm_sales)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot, data = abtest_online)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -16.702 -14.478  -9.626  13.922  64.648 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  16.7017     0.8374  19.944  &lt; 2e-16 ***\n#&gt; chatbotTRUE  -7.0756     1.1796  -5.998 2.79e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.65 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.0348, Adjusted R-squared:  0.03383 \n#&gt; F-statistic: 35.98 on 1 and 998 DF,  p-value: 2.787e-09\n\njtools::effect_plot(lm_sales, pred = chatbot)\n\n\n\n\n\n\n\nThe coefficient of the regression is \\(-7.0756\\) for chatbot = TRUE. This means that the sales dropped for the group of customers that were directed to a chatbot. The result also reflects in the plot.\n\nThe chosen subgroup is mobile users.\n\n\n# Functions used in R for the task\nlm_CATE &lt;- lm(purchase_amount ~ chatbot*mobile_device, data = abtest_online)\nsummary(lm_CATE)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = abtest_online)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                    16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbotTRUE                    -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_deviceTRUE              -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbotTRUE:mobile_deviceTRUE  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08\n\n\n\nLogistic regression of purchase\n\n\n\n# Functions used in R for the task\nlogreg &lt;- glm(purchase ~ chatbot, data = abtest_online, family=binomial)\nsummary(logreg)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = purchase ~ chatbot, family = binomial, data = abtest_online)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.01613    0.08981  -0.180    0.857    \n#&gt; chatbotTRUE -0.98939    0.13484  -7.337 2.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1329.1  on 999  degrees of freedom\n#&gt; Residual deviance: 1273.3  on 998  degrees of freedom\n#&gt; AIC: 1277.3\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\nodds_ratio &lt;- exp(-0.98939)\npercentage &lt;- odds_ratio/(1+odds_ratio)\n\nThe coefficient for chatbot = TRUE is \\(-0.98939\\) which corresponds to the log of odds ratio between the group of customers that used the chatbot and that interacted with human customer service. The log odds is the logarithm of the odds, which is the ratio of something happening to something not happening. The odds ratio equals \\(0.37\\) is less than \\(1\\), which means that it is unlikely that a customer using a chatbot will purchase something. In particular, the odds of purchasing something for customers who didn’t use a chatbot are about \\(27\\%\\) higher than the odds for customers who used a chatbot."
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "\\(P(T \\cap S) = 0.3 \\cdot 0.2 = 0.06\\)\n\\(P(T \\cap \\overline{S}) = 0.7 \\cdot 0.6 = 0.42\\)\n\\(P(\\overline{T} \\cap S) = 0.3 \\cdot 0.8 = 0.24\\)\n\\(P(\\overline{T} \\cap \\overline{S}) = 0.7 \\cdot 0.4 = 0.28\\)\n\\(P(T \\cap S) + P(T \\cap \\overline{S}) + P(\\overline{T} \\cap S) + P(\\overline{T} \\cap \\overline{S}) = 0.06 + 0.42 + 0.24 + 0.28 = 1\\)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "1 Assignment\n\nThe data has 181 rows and 22 columns.\n\n\n# Functions used in R for the task\ncar_prices &lt;- readRDS(\"files/car_prices.rds\")\ndim(car_prices)\n\n#&gt; [1] 181  22\n\n\n\nThere are three data types in the data: integer, numeric, character. Numbers can be represented as different data types. Whole numbers have integer data types, while decimal numbers are represented as numeric data types. Strings are represented as character data types and can store not only letters,symbols or sentences but also numbers. Strings must be enclosed in single or double quotes.\nThe factors that are relevant for the pricing of a car are: car width, engine size, stroke, peak rpm. These four factors are statistically significant at different levels of \\(\\alpha\\) (\\(\\alpha = 0\\) and \\(\\alpha = .001\\)), meaning there is a correlation between the independent variables (carwidth, enginesize, stroke, peakrpm) and the dependent variable price.\n\n\n# Functions used in R for the task\nlm_car_prices &lt;- lm(price ~ ., data = car_prices)\nlm_summary &lt;- summary(lm_car_prices)\n\n\nChosen regressor: peakrpm\n\nThe regressor has integer data type. The values of peakrpm are positive whole numbers without a decimal point.\nAn increase of one unit in peakrpm is related to an \\(2.416\\) increase in price.\nThe above mentioned effect is statistically significant, since the respective p-value is lower than the significance level \\(\\alpha = 0\\).\n\nI get NA as coefficient for the new variable seat_heating. This is due to the fact that some of the assumptions for a linear regression to deliver valid results are not fulfilled since the variable only takes on one unique value. The linearity, homoscedasticity and normality conditions are not fulfilled, since the variable doesn’t provide any variability for the regression model. Due to this lack of information and variability, R cannot find any relationship between independent and dependent variable when performing linear regression.\n\n\n# Functions used in R for the task\ncar_prices &lt;- car_prices %&gt;% mutate(seat_heating = TRUE)\nlm_car_prices &lt;- lm(price ~ ., data = car_prices)\nlm_summary &lt;- summary(lm_car_prices)"
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/01_probability.html#assignment-i",
    "href": "content/01_journal/01_probability.html#assignment-i",
    "title": "Probability Theory",
    "section": "",
    "text": "\\(P(T \\cap S) = 0.3 \\cdot 0.2 = 0.06\\)\n\\(P(T \\cap \\overline{S}) = 0.7 \\cdot 0.6 = 0.42\\)\n\\(P(\\overline{T} \\cap S) = 0.3 \\cdot 0.8 = 0.24\\)\n\\(P(\\overline{T} \\cap \\overline{S}) = 0.7 \\cdot 0.4 = 0.28\\)\n\\(P(T \\cap S) + P(T \\cap \\overline{S}) + P(\\overline{T} \\cap S) + P(\\overline{T} \\cap \\overline{S}) = 0.06 + 0.42 + 0.24 + 0.28 = 1\\)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#assignment-ii",
    "href": "content/01_journal/01_probability.html#assignment-ii",
    "title": "Probability Theory",
    "section": "2.1 Assignment II",
    "text": "2.1 Assignment II\n\nThe percentage of customers using all three devices is \\(0.5\\%\\).\nThe percentage of customers using at least two devices is \\(19.9\\%\\).\nThe percentage of customers using only one device is \\(80.1\\%\\)."
  },
  {
    "objectID": "content/01_journal/01_probability.html#assignment-iii",
    "href": "content/01_journal/01_probability.html#assignment-iii",
    "title": "Probability Theory",
    "section": "3.1 Assignment III",
    "text": "3.1 Assignment III\n\n\\(P(\\overline{A}|B) = \\frac{0.01*(1-0.04)}{0.97*0.04+0.01*(1-0.04)} = 0.198\\)\n\\(P(A|B) = \\frac{0.97*0.04}{0.97*0.04+0.01*(1-0.04)} = 0.802\\)"
  },
  {
    "objectID": "content/01_journal/01_probability_org.html",
    "href": "content/01_journal/01_probability_org.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/01_probability_org.html#header-2",
    "href": "content/01_journal/01_probability_org.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  }
]